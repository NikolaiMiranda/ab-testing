# Metropolis-Hastings: A Theory and Implementation Overview

This project explores the **Metropolis-Hastings (M-H) algorithm** by combining a summary of Siddhartha Chib and Edward Greenberg‚Äôs paper _‚ÄúUnderstanding the Metropolis-Hastings Algorithm‚Äù_ with an implementation of the algorithm in R.

## Summary of the Metropolis-Hastings Algorithm

This section summarizes the core ideas of the M-H algorithm as presented by Chib and Greenberg (1995).

### Goal of the Algorithm

The Metropolis-Hastings algorithm is designed to **simulate samples from complex multivariate probability distributions**, especially when direct sampling is impractical. It constructs a Markov Chain whose limiting distribution converges to the desired target distribution.

---

### The Algorithm

Given a target distribution œÄ(x) we want to sample from:

1. **Initialize** the Markov Chain with an arbitrary value `X[1]`.
2. For each iteration `i`, do the following:
   - Generate a **proposal** `Y` from a candidate-generating distribution `q(Y | X[i])`.
   - Sample `U ~ Uniform(0,1)`.
   - Compute the **acceptance ratio**:

     \[
     \alpha = \min\left(1, \frac{\pi(Y) q(X[i] \mid Y)}{\pi(X[i]) q(Y \mid X[i])}\right)
     \]

   - If `U ‚â§ Œ±`, accept the proposal: `X[i+1] ‚Üê Y`.
   - Otherwise, reject it: `X[i+1] ‚Üê X[i]`.

3. After enough iterations, the samples in `X` approximate the target distribution.

---

### Why It Works: Reversibility

The key theoretical justification is **reversibility**: the idea that the Markov process moves between states `X` and `Y` at equal rates. This ensures the **target distribution is invariant** under the M-H transition kernel.

Reversibility guarantees that under mild conditions (e.g., irreducibility and aperiodicity), the Markov chain converges to the correct distribution.

---

### Choosing a Proposal Distribution

The proposal distribution `q(Y | X)` plays a major role in the **efficiency** of the algorithm. The paper discusses the trade-off involved:

- A **large spread** in the proposal leads to low acceptance rates.
- A **small spread** leads to high acceptance, but slow exploration of the distribution.

As a rule of thumb, an acceptance rate between **0.23 and 0.50** is often considered efficient.

---

### Application: Metropolis-Hastings as an Acceptance-Rejection Method

The paper also shows how M-H can improve the classical **acceptance-rejection method**, which usually requires a well-chosen blanketing distribution (i.e., an envelope over the target distribution). M-H removes this constraint by **adjusting the sampling probabilities via the acceptance ratio**, allowing us to sample without finding a bounding function.

---

## üíª Implementation in R

As a practical exercise, I implemented the Metropolis-Hastings algorithm in R to sample from a posterior distribution based on bacterial count data.

- The **prior** is a Gamma distribution: `Gamma(Œ± = 0.7, Œ≤ = 0.01)`
- The **data** represent bacterial counts across three levels of dilution.
- The **likelihood** is modeled using a custom function reflecting the observed count data.

We use a **Gamma proposal distribution** centered at the current sample with tuned parameters to achieve a reasonable acceptance rate.

### Sampling Code

The core implementation is in [`mcmc_sampler.R`](./mcmc_sampler.R). It includes:
- The likelihood function
- Posterior computation
- Proposal generation
- Metropolis-Hastings loop
- Trace and histogram plots

---

## üìà Example Results

Below are two plots generated by the script:

- **Trace Plot**: Shows how the sampler explores the parameter space.
- **Posterior Histogram**: Approximates the target posterior distribution of Œ∏.

<p align="center">
  <img src="plots/trace_plot.png" width="45%" />
  <img src="plots/posterior_histogram.png" width="45%" />
</p>

---

## Key Takeaways

- The Metropolis-Hastings algorithm is a powerful MCMC tool for simulating from complex distributions.
- Reversibility is the theoretical backbone that guarantees convergence.
- Proposal tuning is crucial for balancing exploration and efficiency.
- M-H can be applied in real-world problems where blanketing distributions are hard to construct.

---

## Reference

Chib, Siddhartha, and Edward Greenberg.  
‚ÄúUnderstanding the Metropolis-Hastings Algorithm.‚Äù  
_The American Statistician_, vol. 49, no. 4, 1995, pp. 327‚Äì335.  
[https://doi.org/10.1080/00031305.1995.10476177](https://doi.org/10.1080/00031305.1995.10476177)

---
